{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "217690be-9836-4e06-930e-ba7efbb37d91",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Note: Cell is tagged to not show up in the mkdocs build\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b58e71",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div class=\"admonition abstract highlight\">\n",
    "    <p class=\"admonition-title\">In short</p>\n",
    "    <p>This tutorial shows how to optimize a Polaris dataset to improve its efficiency.</p>\n",
    "</div>\n",
    "\n",
    "<div class=\"admonition abstract warning\">\n",
    "    <p class=\"admonition-title\">No magic bullet</p>\n",
    "    <p>What works best really depends on the specific dataset you're using and you will benefit from trying out different ways of storing the data.</p>\n",
    "</div>\n",
    "\n",
    "## Datasets that fit in memory\n",
    "Through the Polaris `Subset` class, we aim to provide a _general purpose_ data loader that serves as a good default for a variety of use cases.\n",
    "\n",
    "**As a dataset creator**, it is important to be mindful of some design decisions you can make to improve performance for your downstream users. These design decisions are most impactful!\n",
    "\n",
    "**As a dataset user**, we provide the `Dataset.load_to_memory()` method to load the uncompressed dataset into memory. This is limited though, because there is only so much we can do automatically without risking data integrity.\n",
    "\n",
    "Despite our best efforts to provide a data loader that is as efficient as possible, you will always be able to optimize things further for a specific use case if needed.\n",
    "\n",
    "### _Without_ Zarr\n",
    "Without pointer columns, the best way to optimize your dataset's performance is by making sure you use the appropriate dtype. A smaller memory footprint not only reduces storage requirements, but also speeds up moving data around (e.g. to the GPU or to create `torch.Tensor` objects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c7d338f-8021-4331-a030-289cc9c7e5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04920850-621b-4f08-bc2c-6dfaade87c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dummy dataset with two columns \n",
    "rng = np.random.default_rng(0)\n",
    "col_a = rng.choice(list(range(100)), 10000)\n",
    "col_b = rng.random(10000)\n",
    "table = pd.DataFrame({\"A\": col_a, \"B\": col_b})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877b05eb-794c-4770-81fa-c1bdf5a4e103",
   "metadata": {},
   "source": [
    "By default, Pandas (and NumPy) use the largest dtype available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8531c7b-612b-4ac0-95c1-a085cff6a44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A      int64\n",
       "B    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "640fab44-1fd8-473a-ba57-1f7b8284344f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160132"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b8e83-e08a-48db-805a-a45d36609d79",
   "metadata": {},
   "source": [
    "However, we know that column A only has values between 0 and 99, so we won't need the full `int64` dtype. The `np.int16` is already more appropriate! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cc1132b-ebf8-4bb2-815c-71627dc8a3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100132"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[\"A\"] = table[\"A\"].astype(np.int16)\n",
    "table.memory_usage().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55b5c5d-32fb-4a1b-8e23-f6b1ac0628ba",
   "metadata": {},
   "source": [
    "We managed to reduce the number of bytes by ~60k (or 60KB). **That's 37.5% less!**\n",
    "\n",
    "Now imagine we would be talking about gigabyte-sized dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490fd21e-db29-4539-b514-e83493060a55",
   "metadata": {},
   "source": [
    "### _With_ Zarr\n",
    "If part of the dataset is stored in a Zarr archive - and that Zarr archive fits in memory (remember to optimize the `dtype`) - the most efficient thing to do is to just convert from Zarr to a NumPy array. Zarr is not built to support this use case specifically and NumPy is optimized for it. For more information, see e.g. [this Github issue](https://github.com/zarr-developers/zarr-python/issues/1395).\n",
    "\n",
    "Luckily, you don't have to do this yourself. You can use Polaris its `Dataset.load_to_memory()`.\n",
    "\n",
    "Let's again start by creating a dummy dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "624b55c3-389f-4e2c-bc49-58db2542e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zarr\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "tmpdir =  mkdtemp()\n",
    "\n",
    "# For the ones familiar with Zarr, this is not optimized at all. \n",
    "# If you wouldn't want to convert to NumPy, you would want to \n",
    "# optimize the chunking / compression.\n",
    "\n",
    "path = os.path.join(tmpdir, \"data.zarr\")\n",
    "root = zarr.open(path, \"w\")\n",
    "root.array(\"A\", rng.random(10000))\n",
    "root.array(\"B\", rng.random(10000));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf9f62e-7be3-4d85-b41c-4e45a73e5f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polaris.dataset import create_dataset_from_file\n",
    "\n",
    "root_path = os.path.join(tmpdir, \"data\", \"data.zarr\")\n",
    "dataset = create_dataset_from_file(path, zarr_root_path=root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2e441ef-7a9f-4306-81c6-5f2414655130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polaris.dataset import Subset\n",
    "\n",
    "subset = Subset(dataset, np.arange(len(dataset)), \"A\", \"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb12a2d-733b-4e52-83f1-f6a3a3e02054",
   "metadata": {},
   "source": [
    "For the sake of this example, we will use PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c562fb4-0a7e-49a7-81bd-0a65cf8c8109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(subset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f3cca7-4a3f-46ba-b50f-15f6af99120d",
   "metadata": {},
   "source": [
    "Let's see how fast this is!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f53c3249-aa24-4323-8acf-7593bdd12dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45 s ± 22 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for batch in dataloader: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465116b-e69f-47e7-a77f-a93f69a55ec3",
   "metadata": {},
   "source": [
    "That's pretty slow... Let's see if Polaris its optimization helps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "861ecad6-a141-4527-a583-19ec7ed7ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.load_to_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be163e3a-b054-4496-9bc4-bfdc063a42aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.4 ms ± 2.45 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for batch in dataloader: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85e1089-9969-4ed0-999d-7b6327148a37",
   "metadata": {},
   "source": [
    "That's a lot faster! \n",
    "\n",
    "Now all that's left to do, is to clean up the temporary directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24781758-8c10-447f-a56b-d20da5fa297f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "rmtree(tmpdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f8babc-ae30-402e-80e6-1039ac60207e",
   "metadata": {},
   "source": [
    "## Datasets that fit on a local disk\n",
    "\n",
    "For datasets that don't fit in memory, but that can be stored on a local disk, the most impactful design decision is how the dataset is chunked. \n",
    "\n",
    "Zarr datasets are chunked. When you try to load one piece of data, the entire chunk that data is part of has to be loaded into memory and decompressed. Remember that in ML, data access is typically random, which is a terrible access pattern because you are likely to reload chunks into memory.\n",
    "\n",
    "Most efficient is thus to chunk the data such that each chunk only contains a single data point.\n",
    "\n",
    "- Benefit: No longer induce a performance penalty due to loading additional data into memory that it might not need.\n",
    "- Downside: You might be able to compress the data more if you can consider similarities across data points while compressing.\n",
    "\n",
    "**A note on rechunking**: Within Polaris, you do not have control over how a dataset on the Hub is chunked. In that case, rechunking is needed. This can induce a one-time, but nevertheless big performance penalty (see also the [Zarr docs](https://zarr.readthedocs.io/en/stable/tutorial.html#changing-chunk-shapes-rechunking)). I don’t expect this to be an issue in the short-term given the size of the dataset we will be working with, but Zarr recommends using the [rechunker](https://github.com/pangeo-data/rechunker?tab=readme-ov-file) Python package to improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160b3cb4-0069-402e-ae35-c5410d68285a",
   "metadata": {},
   "source": [
    "## Remote Datasets\n",
    "In this case, you really benefit from improving memory storage by trying different compressors.\n",
    "\n",
    "See also [this article](https://earthmover.io/blog/cloud-native-dataloader)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72767ef2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The End. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
